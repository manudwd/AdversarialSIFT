{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdi-KdEHJsoF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageOps\n",
        "import glob\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import logging\n",
        "from resnet import resnet18"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQcoeYuQ_mfn",
        "outputId": "339d309c-b1bf-42cd-827e-d52a9b747eaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_dataloader(num_workers=4, train_batch_size=128, eval_batch_size=256):\n",
        "\n",
        "    data_dir=r'/content/drive/MyDrive/DataRedo/'\n",
        "    \n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop((256,256)),\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize((256,256)),\n",
        "            # transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "\n",
        "    train_set = datasets.ImageFolder(os.path.join(data_dir, \"train\"),\n",
        "                                         data_transforms[\"train\"])\n",
        "    # train_sampler = torch.utils.data.RandomSampler(train_set)\n",
        "    # train_set, val_set = train_val_split()\n",
        "    train_loaders = torch.utils.data.DataLoader(train_set, \n",
        "                                                shuffle=True,\n",
        "                                                batch_size=train_batch_size,\n",
        "                                                num_workers=num_workers)\n",
        "    val_set = datasets.ImageFolder(os.path.join(data_dir, \"val\"),\n",
        "                                         data_transforms[\"val\"])\n",
        "    # train_sampler = torch.utils.data.RandomSampler(train_set)\n",
        "    # train_set, val_set = train_val_split()\n",
        "    val_loader = torch.utils.data.DataLoader(val_set, \n",
        "                                                shuffle=True,\n",
        "                                                batch_size=eval_batch_size,\n",
        "                                                num_workers=num_workers)\n",
        "\n",
        "    return train_loaders, val_loader"
      ],
      "metadata": {
        "id": "Otn3jeI7qPX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "def prepare_dataloader(num_workers=4, train_batch_size=128, eval_batch_size=256):\n",
        "    data_dir=r'/content/drive/MyDrive/DataRedo/'\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop((256,256)),\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize((256,256)),\n",
        "            # transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "\n",
        "    train_set = datasets.ImageFolder(os.path.join(data_dir, \"train\"),\n",
        "                                          data_transforms[\"train\"])\n",
        "    train_loaders = torch.utils.data.DataLoader(train_set, \n",
        "                                                shuffle=True,\n",
        "                                                batch_size=train_batch_size,\n",
        "                                                num_workers=num_workers)\n",
        "    \n",
        "    val_set = datasets.ImageFolder(os.path.join(data_dir, \"val\"),\n",
        "                                          data_transforms[\"val\"])\n",
        "    \n",
        "    val_loaders = torch.utils.data.DataLoader(val_set,\n",
        "                                              shuffle=True,\n",
        "                                              batch_size=eval_batch_size,\n",
        "                                              num_workers=num_workers)\n",
        "    \n",
        "    return train_loaders, val_loaders"
      ],
      "metadata": {
        "id": "ToIXZ4bXo-_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_random_seeds(random_seed=0):\n",
        "\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        " \n",
        "\n",
        "def evaluate_model(model, test_loader, device, criterion=None):\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    running_loss = 0\n",
        "    running_corrects = 0\n",
        "    class_names = ['Dog', 'Human', 'Deer', 'Cat']\n",
        "    # class_names = [name[37:] for name in glob.glob(r'/content/drive/MyDrive/DataRedo/train/*')]\n",
        "    class_names = dict(zip(range(0,len(class_names)), class_names))\n",
        "    \n",
        "    for inputs, labels in test_loader:\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        if criterion is not None:\n",
        "            loss = criterion(outputs, labels).item()\n",
        "        else:\n",
        "            loss = 0\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    eval_loss = running_loss / len(test_loader.dataset)\n",
        "    eval_accuracy = running_corrects / len(test_loader.dataset)\n",
        "\n",
        "    return eval_loss, eval_accuracy\n",
        "\n",
        "def write_checkpoint(model, optimizer, epoch, scheduler):\n",
        "  state = {'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
        "             'optimizer': optimizer.state_dict(), 'scheduler': scheduler.state_dict(), }\n",
        "  filename = '/content/model_'\n",
        "  \n",
        "  torch.save(state, filename + f'CP_epoch{epoch + 1}.pth')\n",
        "\n",
        "\n",
        "def load_checkpoint(model, optimizer, scheduler, filename='/content/checkpoint.pth'):\n",
        "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
        "    start_epoch = 0\n",
        "    if os.path.isfile(filename):\n",
        "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
        "        checkpoint = torch.load(filename)\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        scheduler = checkpoint['scheduler']\n",
        "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "                  .format(filename, checkpoint['epoch']))\n",
        "        \n",
        "        \n",
        "    else:\n",
        "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
        "\n",
        "    return model, optimizer, start_epoch, scheduler\n",
        "\n",
        "def train_model(model, train_loader, test_loader, device, learning_rate=1e-1, num_epochs=200):\n",
        "\n",
        "    # The training configurations were not carefully selected.\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10.\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[65, 75], gamma=0.75, last_epoch=-1)\n",
        "    # optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=device, criterion=criterion)\n",
        "    print(\"Epoch: {:02d} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(-1, eval_loss, eval_accuracy))\n",
        "\n",
        "    load_model = input('Load a model?')\n",
        "    \n",
        "    start_epoch=0\n",
        "    if load_model:\n",
        "      model, optimizer, start_epoch, scheduler = load_checkpoint(model=model, scheduler=scheduler, optimizer=optimizer)\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "\n",
        "        if  epoch//10 == 0:\n",
        "          write_checkpoint(model=model, epoch=epoch, scheduler=scheduler, optimizer=optimizer)          \n",
        "          # model, optimizer, epoch, scheduler = load_checkpoint(model=model, scheduler=scheduler, optimizer=optimizer)    \n",
        "          \n",
        "          for state in optimizer.state.values():\n",
        "            for k, v in state.items():\n",
        "                if isinstance(v, torch.Tensor):\n",
        "                    state[k] = v.to(device)\n",
        "        # Training\n",
        "        model.train()\n",
        "\n",
        "        running_loss = 0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = torch.FloatTensor(inputs)\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "        train_accuracy = running_corrects / len(train_loader.dataset)\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        eval_loss, eval_accuracy = evaluate_model(model=model, test_loader=test_loader, device=device, criterion=criterion)\n",
        "\n",
        "        # Set learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        print(\"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}\".format(epoch, train_loss, train_accuracy, eval_loss, eval_accuracy))\n",
        "\n",
        "    return model\n",
        "\n",
        "def calibrate_model(model, loader, device=torch.device(\"cpu:0\")):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    \n",
        "    for inputs,labels in loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        _ = model(inputs)\n",
        "\n",
        "def measure_inference_latency(model,\n",
        "                              device,\n",
        "                              input_size=(1, 3, 32, 32),\n",
        "                              num_samples=100,\n",
        "                              num_warmups=10):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    x = torch.rand(size=input_size).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_warmups):\n",
        "            _ = model(x)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        for _ in range(num_samples):\n",
        "            _ = model(x)\n",
        "            torch.cuda.synchronize()\n",
        "        end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_time_ave = elapsed_time / num_samples\n",
        "\n",
        "    return elapsed_time_ave\n",
        "\n",
        "def save_model(model, model_dir, model_filename):\n",
        "\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "    model_filepath = os.path.join(model_dir, model_filename)\n",
        "    torch.save(model.state_dict(), model_filepath)\n",
        "\n",
        "def load_model(model, model_filepath, device):\n",
        "\n",
        "    model.load_state_dict(torch.load(model_filepath, map_location=device))\n",
        "\n",
        "    return model\n",
        "\n",
        "def save_torchscript_model(model, model_dir, model_filename):\n",
        "\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "    model_filepath = os.path.join(model_dir, model_filename)\n",
        "    torch.jit.save(torch.jit.script(model), model_filepath)\n",
        "\n",
        "def load_torchscript_model(model_filepath, device):\n",
        "\n",
        "    model = torch.jit.load(model_filepath, map_location=device)\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_model(num_classes=10):\n",
        "\n",
        "    # The number of channels in ResNet18 is divisible by 8.\n",
        "    # This is required for fast GEMM integer matrix multiplication.\n",
        "    # model = torchvision.models.resnet18(pretrained=False)\n",
        "    model = resnet18(num_classes=num_classes, pretrained=False)\n",
        "\n",
        "    # We would use the pretrained ResNet18 as a feature extractor.\n",
        "    # for param in model.parameters():\n",
        "    #     param.requires_grad = False\n",
        "    \n",
        "    # Modify the last FC layer\n",
        "    # num_features = model.fc.in_features\n",
        "    # model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "    return model\n",
        "\n",
        "class QuantizedResNet18(nn.Module):\n",
        "    def __init__(self, model_fp32):\n",
        "        super(QuantizedResNet18, self).__init__()\n",
        "        # QuantStub converts tensors from floating point to quantized.\n",
        "        # This will only be used for inputs.\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        # DeQuantStub converts tensors from quantized to floating point.\n",
        "        # This will only be used for outputs.\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "        # FP32 model\n",
        "        self.model_fp32 = model_fp32\n",
        "\n",
        "    def forward(self, x):\n",
        "        # manually specify where tensors will be converted from floating\n",
        "        # point to quantized in the quantized model\n",
        "        x = self.quant(x)\n",
        "        x = self.model_fp32(x)\n",
        "        # manually specify where tensors will be converted from quantized\n",
        "        # to floating point in the quantized model\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "def model_equivalence(model_1, model_2, device, rtol=1e-05, atol=1e-08, num_tests=100, input_size=(1,3,32,32)):\n",
        "\n",
        "    model_1.to(device)\n",
        "    model_2.to(device)\n",
        "\n",
        "    for _ in range(num_tests):\n",
        "        x = torch.rand(size=input_size).to(device)\n",
        "        y1 = model_1(x).detach().cpu().numpy()\n",
        "        y2 = model_2(x).detach().cpu().numpy()\n",
        "        if np.allclose(a=y1, b=y2, rtol=rtol, atol=atol, equal_nan=False) == False:\n",
        "            print(\"Model equivalence test sample failed: \")\n",
        "            print(y1)\n",
        "            print(y2)\n",
        "            return False\n",
        "\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "z4rGDVLYJ5yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "BEM3aHmUcRgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "  ########################Intialization#########################################\n",
        "\n",
        "    random_seed = 42\n",
        "    num_classes = 4\n",
        "    cuda_device = torch.device(\"cuda:0\")\n",
        "    cpu_device = torch.device(\"cpu:0\")\n",
        "\n",
        "\n",
        "    model_dir = \"saved_models\"\n",
        "    model_filename = \"RGB_RedoData_resnet18.pt\"\n",
        "    # quantized_model_filename = \"resnet18_quantized_spatial_pyramid.pt\"\n",
        "    # model_filepath = os.path.join(model_dir, model_filename)\n",
        "    model_filepath = model_filename\n",
        "    # quantized_model_filepath = os.path.join(model_dir, quantized_model_filename)\n",
        "  \n",
        "    set_random_seeds(random_seed=random_seed)\n",
        "\n",
        "    #Create an instance of sift\n",
        "    # sift = cv.xfeatures2d.SIFT_create(nOctaveLayers=12, edgeThreshold=20, sigma=1.4)\n",
        "\n",
        "    # Create an untrained model.\n",
        "    model = create_model(num_classes=num_classes)\n",
        "\n",
        "    train_loader, test_loader = prepare_dataloader(num_workers=4, train_batch_size=16, eval_batch_size=32)\n",
        "    \n",
        "    ###################################Training of model END#####################\n",
        "    print(\"Training Model...\")\n",
        "    \n",
        "    model = train_model(model=model, train_loader=train_loader, test_loader=test_loader, device=cuda_device, learning_rate=1e-1, num_epochs=80)\n",
        "\n",
        "    \n",
        "    model = train_model(model=model, train_loader=train_loader, test_loader=test_loader, device=cuda_device, learning_rate=1e-1, num_epochs=80)\n",
        "    # # Save model.\n",
        "    save_model(model=model, model_dir=model_dir, model_filename=model_filename)\n",
        "    # Load a pretrained model.\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    torch.cuda.empty_cache()\n",
        "    main()"
      ],
      "metadata": {
        "id": "WL6aDcKZKMjU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030f8061-bb0d-4ab9-808e-0257ea387a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model...\n",
            "Epoch: -1 Eval Loss: 1.549 Eval Acc: 0.236\n",
            "Load a model?\n",
            "=> no checkpoint found at '/content/checkpoint.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RTq0va56QK9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non SIFT Detection"
      ],
      "metadata": {
        "id": "X6lbhuiiMBNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "from torchvision.io import read_image\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "cuda_device = torch.device(\"cuda:0\")\n",
        "class_names= ['Cat', 'Deer', 'Dog', 'Human', 'Owl', 'Racoon']\n",
        "    \n",
        "model = torch.load('/content/adverserial_model.pt', map_location=cuda_device)\n",
        "\n",
        "img_cat = Image.open(\"/content/cat.jpg\").convert('RGB')\n",
        "preprocess = transforms.Compose([\n",
        "        transforms.Resize(256,256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )])\n",
        "#\n",
        "# Pass the image for preprocessing and the image preprocessed\n",
        "#\n",
        "img_cat_preprocessed = preprocess(img_cat)\n",
        "#\n",
        "# Reshape, crop, and normalize the input tensor for feeding into network for evaluation\n",
        "#\n",
        "batch_img_cat_tensor = torch.unsqueeze(img_cat_preprocessed, 0)\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "out = model(batch_img_cat_tensor)\n",
        "_, index = torch.max(out, 1)\n",
        "\n",
        "#\n",
        "# Find the score in terms of percentage by using torch.nn.functional.softmax function\n",
        "# which normalizes the output to range [0,1] and multiplying by 100\n",
        "#\n",
        "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "#\n",
        "# Print the name along with score of the object identified by the model\n",
        "#\n",
        "print(class_names[index[0]], percentage[index[0]].item())\n",
        "#\n",
        "# Print the top 5 scores along with the image label. Sort function is invoked on the torch to sort the scores.\n",
        "#\n",
        "_, indices = torch.sort(out, descending=True)\n",
        "[(class_names[idx], percentage[idx].item()) for idx in indices[0][:5]]\n",
        "\n",
        "# bounding box in (xmin, ymin, xmax, ymax) format\n",
        "bbox1 = [30, 45, 200, 200]\n",
        "bbox = [bbox1]\n",
        "bbox = torch.tensor(bbox, dtype=torch.int)\n",
        "labels = class_names\n",
        "pred_label = [class_names[idx] for idx in indices[0][:1]]\n",
        "img = read_image(\"/content/cat.jpg\")\n",
        "img=draw_bounding_boxes(img, bbox,width=3,labels= pred_label,colors=[(255,0,0),(0,255,0)],fill =True,font_size=20)\n",
        "img = torchvision.transforms.ToPILImage()(img)\n",
        "img"
      ],
      "metadata": {
        "id": "Ng9olp_iMD_S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}